{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "24b32597",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import Bidirectional, LSTM\n",
    "from tensorflow.keras.layers import Dense, Dropout, Input\n",
    "from tensorflow.keras.layers import Concatenate, Add, GRU\n",
    "\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fa779c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing add features function from Feature engineering file\n",
    "import ipynb\n",
    "from ipynb.fs.full.Feature_Engineering import add_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c57fa0b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv(\"C:\\\\Users\\\\Ajay Kallepalli\\\\Documents\\\\GitHub\\\\Kaggle Data\\\\test.csv\")\n",
    "train_data = pd.read_csv(\"C:\\\\Users\\\\Ajay Kallepalli\\\\Documents\\\\GitHub\\\\Kaggle Data\\\\train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8337bbbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6aba03b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data...\n",
      "\n",
      "Step-1...Completed\n",
      "Step-2...Completed\n",
      "Step-3...Completed\n",
      "Step-4...Completed\n",
      "Step-5...Completed\n",
      "Step-6...Completed\n",
      "Step-7...Completed\n",
      "Step-8...Completed\n",
      "\n",
      "Test data...\n",
      "\n",
      "Step-1...Completed\n",
      "Step-2...Completed\n",
      "Step-3...Completed\n",
      "Step-4...Completed\n",
      "Step-5...Completed\n",
      "Step-6...Completed\n",
      "Step-7...Completed\n",
      "Step-8...Completed\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"Train data...\\n\")\n",
    "train = add_features(train_data)\n",
    "print(\"\\nTest data...\\n\")\n",
    "test = add_features(test_data)\n",
    "del train_data\n",
    "del test_data\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7ae5aab0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (6036000, 64) \n",
      "test: (4024000, 64)\n"
     ]
    }
   ],
   "source": [
    "targets = train[['pressure']].to_numpy().reshape(-1, 80)\n",
    "\n",
    "train.drop(['pressure','id', 'breath_id','one','count',\n",
    "            'breath_id_lag','breath_id_lag2','breath_id_lagsame',\n",
    "            'breath_id_lag2same'], axis=1, inplace=True)\n",
    "\n",
    "test = test.drop(['id', 'breath_id','one','count','breath_id_lag',\n",
    "                  'breath_id_lag2','breath_id_lagsame',\n",
    "                  'breath_id_lag2same'], axis=1)\n",
    "\n",
    "print(f\"train: {train.shape} \\ntest: {test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "89f9244a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: (75450, 80, 64) \n",
      "test: (50300, 80, 64) \n",
      "targets: (75450, 80)\n"
     ]
    }
   ],
   "source": [
    "scaler = RobustScaler()\n",
    "train = scaler.fit_transform(train)\n",
    "test = scaler.transform(test)\n",
    "\n",
    "train = train.reshape(-1, 80, train.shape[-1])\n",
    "test = test.reshape(-1, 80, train.shape[-1])\n",
    "\n",
    "print(f\"train: {train.shape} \\ntest: {test.shape} \\ntargets: {targets.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4d15e0e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Min pressure: -1.8957443237304688\n",
      "Max pressure: 64.82099151611328\n",
      "Pressure step: 0.07030248641967773\n",
      "Unique values:  950\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pressure = targets.squeeze().reshape(-1,1).astype('float32')\n",
    "\n",
    "P_MIN = np.min(pressure)\n",
    "P_MAX = np.max(pressure)\n",
    "P_STEP = (pressure[1] - pressure[0])[0]\n",
    "print('Min pressure: {}'.format(P_MIN))\n",
    "print('Max pressure: {}'.format(P_MAX))\n",
    "print('Pressure step: {}'.format(P_STEP))\n",
    "print('Unique values:  {}'.format(np.unique(pressure).shape[0]))\n",
    "\n",
    "del pressure\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4be1746",
   "metadata": {},
   "source": [
    "### Configurating Hardware"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3914a21b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on 1 replicas\n",
      "Batch Size: 512\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    tpu_strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "    BATCH_SIZE = tpu_strategy.num_replicas_in_sync * 64\n",
    "    print(\"Running on TPU:\", tpu.master())\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")\n",
    "    \n",
    "except ValueError:\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "    BATCH_SIZE = 512\n",
    "    print(f\"Running on {strategy.num_replicas_in_sync} replicas\")\n",
    "    print(f\"Batch Size: {BATCH_SIZE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "750acf8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dnn_model():\n",
    "    \n",
    "    x_input = Input(shape=(train.shape[-2:]))\n",
    "    \n",
    "    x1 = Bidirectional(LSTM(units=768, return_sequences=True))(x_input)\n",
    "    x2 = Bidirectional(LSTM(units=512, return_sequences=True))(x1)\n",
    "    x3 = Bidirectional(LSTM(units=256, return_sequences=True))(x2)\n",
    "    \n",
    "    z2 = Bidirectional(GRU(units=256, return_sequences=True))(x2)\n",
    "    z3 = Bidirectional(GRU(units=128, return_sequences=True))(Add()([x3, z2]))\n",
    "    \n",
    "    x = Concatenate(axis=2)([x3, z2, z3])\n",
    "    x = Bidirectional(LSTM(units=192, return_sequences=True))(x)\n",
    "    \n",
    "    x = Dense(units=128, activation='selu')(x)\n",
    "    \n",
    "    x_output = Dense(units=1)(x)\n",
    "\n",
    "    model = Model(inputs=x_input, outputs=x_output, \n",
    "                  name='DNN_Model')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "871f1079",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"DNN_Model\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            [(None, 80, 64)]     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional (Bidirectional)   (None, 80, 1536)     5117952     input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_1 (Bidirectional) (None, 80, 1024)     8392704     bidirectional[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_2 (Bidirectional) (None, 80, 512)      2623488     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_3 (Bidirectional) (None, 80, 512)      1969152     bidirectional_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "add (Add)                       (None, 80, 512)      0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_4 (Bidirectional) (None, 80, 256)      493056      add[0][0]                        \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 80, 1280)     0           bidirectional_2[0][0]            \n",
      "                                                                 bidirectional_3[0][0]            \n",
      "                                                                 bidirectional_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "bidirectional_5 (Bidirectional) (None, 80, 384)      2262528     concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "dense (Dense)                   (None, 80, 128)      49280       bidirectional_5[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 80, 1)        129         dense[0][0]                      \n",
      "==================================================================================================\n",
      "Total params: 20,908,289\n",
      "Trainable params: 20,908,289\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = dnn_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05253dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    VERBOSE = 0\n",
    "    test_preds = []\n",
    "    kf = KFold(n_splits=7, shuffle=True, random_state=2021)\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(train, targets)):\n",
    "        X_train, X_valid = train[train_idx], train[test_idx]\n",
    "        y_train, y_valid = targets[train_idx], targets[test_idx]\n",
    "        \n",
    "        model = dnn_model()\n",
    "        model.compile(optimizer=\"adam\", loss=\"mae\")\n",
    "\n",
    "        lr = ReduceLROnPlateau(monitor=\"val_loss\", factor=0.75, \n",
    "                               patience=10, verbose=VERBOSE)\n",
    "        \n",
    "        save_locally = tf.saved_model.SaveOptions(experimental_io_device='/job:localhost')\n",
    "        chk_point = ModelCheckpoint(f'./Bidirect_LSTM_model_{fold+1}C.h5', options=save_locally, \n",
    "                                    monitor='val_loss', verbose=VERBOSE, \n",
    "                                    save_best_only=True, mode='min')\n",
    "\n",
    "        es = EarlyStopping(monitor=\"val_loss\", patience=50, \n",
    "                           verbose=VERBOSE, mode=\"min\", \n",
    "                           restore_best_weights=True)\n",
    "        \n",
    "        model.fit(X_train, y_train, \n",
    "                  validation_data=(X_valid, y_valid), \n",
    "                  epochs=300,\n",
    "                  verbose=VERBOSE,\n",
    "                  batch_size=BATCH_SIZE, \n",
    "                  callbacks=[lr, chk_point, es])\n",
    "        \n",
    "        load_locally = tf.saved_model.LoadOptions(experimental_io_device='/job:localhost')\n",
    "        model = load_model(f'./Bidirect_LSTM_model_{fold+1}C.h5', options=load_locally)\n",
    "        \n",
    "        y_true = y_valid.squeeze().reshape(-1, 1)\n",
    "        y_pred = model.predict(X_valid, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1)\n",
    "        score = mean_absolute_error(y_true, y_pred)\n",
    "        print(f\"Fold-{fold+1} | OOF Score: {score}\")\n",
    "        \n",
    "        test_preds.append(model.predict(test, batch_size=BATCH_SIZE).squeeze().reshape(-1, 1).squeeze())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "328307d3",
   "metadata": {},
   "source": [
    "### Creating submission files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97af9b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('../input/ventilator-pressure-prediction/sample_submission.csv')\n",
    "submission[\"pressure\"] = sum(test_preds)/7\n",
    "submission.to_csv('mean_submission.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1323140",
   "metadata": {},
   "outputs": [],
   "source": [
    "submission[\"pressure\"] = np.median(np.vstack(test_preds),axis=0)\n",
    "submission[\"pressure\"] = np.round((submission.pressure - P_MIN)/P_STEP) * P_STEP + P_MIN\n",
    "submission[\"pressure\"] = np.clip(submission.pressure, P_MIN, P_MAX)\n",
    "submission.to_csv('median_submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
